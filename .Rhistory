library("XLConnect", lib.loc="/Library/Frameworks/R.framework/Versions/2.14/Resources/library")
remove.packages("XLConnectJars")
library("XLConnect", lib.loc="/Library/Frameworks/R.framework/Versions/2.14/Resources/library")
detach("package:XLConnect", unload=TRUE)
remove.packages("XLConnect")
install.packages("XLConnect")
library("XLConnectJars", lib.loc="/Library/Frameworks/R.framework/Versions/2.14/Resources/library")
library("XLConnect", lib.loc="/Library/Frameworks/R.framework/Versions/2.14/Resources/library")
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/2.14/Resources/library")
table(StC$Index)
9.49+4.99+14.98+28.49
70629+775+316+411+1064-349
library (ILSR)
library (ISLR)
attach(Wage)
wage = Wage
fit = lm(wage~poly(age, 4), data=Wage)
poly(age, 4)
?coef
coef(summary(fit))
?poly
poly = poly(age, 4)
poly = poly(age, 3)
poly = poly(age, 2)
head(poly)
poly = poly(age, 1)
head(poly)
plot(poly)
poly = poly(age, 2)
head(poly)
plot(poly)
poly = poly(1, 2)
head(poly)
plot(poly)
poly = poly(10, 2)
poly = poly(10, 4)
poly = poly(2, 4)
fit = lm(wage~poly(age, 4), data=Wage)
coef(summary(fit))
poly = poly(age, 4)
head(poly)
plot(poly)
fit
str(fit)
fit = lm(wage~poly(age, 4), data=Wage, raw=T)
fit = lm(wage~poly(age, 4), raw=T,data=Wage)
fit = lm(wage~poly(age, 4, raw=T), data=Wage)
coef(summary(fit))
poly = poly(age, 4)
head(poly)
plot(poly)
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelimes[2])
age.grid=seq(from=agelims[1], to=agelies[2])
age.grid=seq(from=agelims[1], to=agelims[2])
age.grid
?seq
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
list(age=age.grid)
t = list(age=age.grid)
t
t = list(age=age.grid, foo=age.grid^2)
t$foo
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4,5,1,1), oma-c(0,0,4,0))
par(mfrow=c(1,2), mar=c(4.5,4,5,1,1), oma=c(0,0,4,0))
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
rm(wage)
attach(Wage)
fit = lm(wage~poly(age, 4, raw=T), data=Wage)
coef(summary(fit))
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial", outer=T)
lines(age.grid, preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue", lty=3)
?matlines
?anova
fit.1=lm(wage~age, data=Wage)
fit.2=lm(wage~poly(age, 2, raw=T), data=Wage))
fit.2=lm(wage~poly(age, 2, raw=T), data=Wage)
fit.3=lm(wage~poly(age, 3, raw=T), data=Wage)
fit.4=lm(wage~poly(age, 4, raw=T), data=Wage)
fit.5=lm(wage~poly(age, 5, raw=T), data=Wage)
anova(fit.1,fit.2,fit.3,fit.4,fit.5)
print(anova)
fit=glm(I(wage>250)~poly(age,4), data=Wage, family=binomial)
preds=predict(fit,newdata=list(age=age.grid),se=T)
pfit=exp(pred$fit)/(1+exp(preds$fit))
pfit=exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
se.bands=exp(se.bands.logit)/(1+exp(se.bands.logit))
plot(age,I(wage>250), xlim=agelims, type="n", ylim=c(0,.2))
points(jitter(age), I((wage>250)/5), cex=.5,pch="|", col="darkgrey")
lines(age.grid, pfit,lwd=2,col="blue")
matlines(age.grid, se.bands, lwd=1, col="blue",lty=3)
?cut
library(splines)
fit=lm(wage~bs(age,knots=c(26,40,60)),data=Wage)
pred=predict(fit,newdata=list(age=age.grid),se=T)
plot(age,wage,col="grey")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
?attr
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid), se=T)
lines(age.grid,pred$fit2, col="red", lwd=2)
lines(age.grid,pred2$fit, col="red", lwd=2)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Smoothing Spline")
fit=smooth.spline(age,wage,df=16)
fit2=smooth.spline(age,wage,cv=TRUE)
fit2$df
lines(fit,col="red"lwd=2)
lines(fit,col="red",lwd=2)
lines(fit2,col="blue",lwd=2)
legend("topright", legend=c("16 DF", "6.8 DF"), col=c("red","blue"), lty=1, lwd=2, cex=.8)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Local Regression")
fit=loess(wage~age,span=.2,data=Wage)
fit2=loess(wage~age,span=.5,data=Wage)
lines(age.grid,predict(fit,data.frame(age=age.grid)),col="red",lwd=2)
lines(age.grid,predict(fit2,data.frame(age=age.grid)),col="blue",lwd=2)
legend("topright", legend=c("Span=0.2","Span=0.5"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
?ns
gam1=lm(wage~ns(year,4)+ns(age,5)+education, data=Wage)
test=predict(gam1,newdata=list(age=age.grid),se=T)
library(gam)
install.packages("gam")
library(gam)
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE, col="red")
table(Wage$year)
gam1=lm(wage~ns(year,4)+ns(age,5)+education,data=Wage)
plot.gam(gam1,se=TRUE,col+"red")
plot.gam(gam1,se=TRUE,col="red")
gam.m1(gam(wage~s(age,5)+education, data=Wage))
gam.m1=gam(wage~s(age,5)+education, data=Wage))
gam.m1=gam(wage~s(age,5)+education, data=Wage)
gam.m2=gam(wage~year+s(age,5)+education,data=Wage)
anova(gam.m1,gam.m2,gam.m3,test="F")
summary(gam.m3)
preds=predict(gam.m2,newdata=Wage)
gam.lo=gam(wage~s(year,df=4)+lo(age,span=0.7)+education,data=Wage)
plot.gam(gam.lo,se=TRUE,col="green")
gam.lo.i=gam(wage~lo(year,age,span=0.5)+education,data=Wage)
plot(gam.lo.i)
library(akima)
install.packages("akima")
library(akima)
plot(gam.lo.i)
gam.lr=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage)
par(mfrow=c(1,3))
plot(gam.lr,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+edcuation,family=binomial,data=Wage,subset=(education!="1. < HS Grad"))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!="1. < HS Grad"))
plot(gam.lr.s,se=T,col="green")
summary(Auto)
pairs(Auto)
fit = lm(wage~poly(age, 4, raw=T), data=Wage)
coef(summary(fit))
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial", outer=T)
lines(age.grid, preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue", lty=3)
attach(Auto)
?xlim
plot(mpg,accleration,cex=.5,col="darkgrey")
plot(mpg,acceleration,cex=.5,col="darkgrey")
fit = lm(mpg~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
str(Auto)
summary(Auto)
table(Auto$mpg)
table(Auto$year)
plot(year,acceleration,cex=.5,col="darkgrey")
plot(year,mpg,cex=.5,col="darkgrey")
plot(year,weight,cex=.5,col="darkgrey")
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(year,acceleration,xlim=yearlims,cex=.5,col="darkgrey")
title("Degree-6 Polynomial", outer=T)
lines(year.grid, preds$fit,lwd=2,col="blue")
matlines(year.grid,se.bands,lwd=1,col="blue", lty=3)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(year,acceleration,xlim=yearlims,cex=.5,col="darkgrey")
title("Degree-6 Polynomial", outer=T)
lines(year.grid, preds$fit,lwd=2,col="blue")
summary(Auto)
pairs(Auto) #consider acceleration, year, mpg
attach(Auto)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
summary(fit)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
newdata=list(year=year.grid)
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
fit = lm(wage~poly(age, 4, raw=T), data=Wage)
coef(summary(fit))
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
newdata=list(year=year.grid)
newdata=list(age=age.grid)
age.grid=seq(from=agelims[1], to=agelims[2])
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelims[2])
newdata=list(age=age.grid)
newdata=list(year=year.grid)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
fit = lm(year~poly(acceleration, 6, raw=T), data=Auto)
coef(summary(fit))
yearlims=range(year)
year.grid=seq(from=yearlims[1], to=yearlims[2])
preds = predict(fit, newdata=list(year=year.grid), se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(year,acceleration,xlim=yearlims,cex=.5,col="darkgrey")
title("Degree-6 Polynomial", outer=T)
lines(year.grid, preds$fit,lwd=2,col="blue")
matlines(year.grid,se.bands,lwd=1,col="blue", lty=3)
pred$fit
preds$fit
fit = lm(wage~poly(age, 4, raw=T), data=Wage)
coef(summary(fit))
agelims=range(age)
age.grid=seq(from=agelims[1], to=agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
summary(Wage)
str(Wage)
# path to kaggle data and other files
setwd("C:\\Users\\mlewo_000\\Documents\\GitHub\\https---github.com-MatthewSchumwinger-towerProperty\\towerProperty")
setwd("~/Documents/towerProperty") # Matt's wd path
source("config.r")
source("helpers.r")
source("data.r")
library(gbm)
setConfigForMyEnvironment() # special helper function for Matt's environment
includeLibraries()
filter = ""
rawData = readData(FALSE)
allPredictors = preparePredictors(rawData, filter)
allData = prepareSplits(rawData, allPredictors, c(0))
filter = "199|200|2010|2011|add_no|conc|TELEMAN|JOHANN|ROSSINI|add_price|conc_missed|ever.bought.subs|num.bought.ticket|add_tickets|add_tickets_seats|section_2013_2014|multiple.subs|billing.city|is.us|relationship|outside|City|State|Lat|Long|geo|hotspot"
useLogTransform = F
trees = 3000
bagfrac = 0.5
trainfrac = 1.0
shrinkage = 0.001
depth = 10
distrib = "tdist"
minobsinnode = 4
df = 1
numfolds = 10
clean = T
rawData = readData(useLogTransform)
# for some reasom gbm is not picking that up in the function
polyOrder = 2
formula = prepareFormula(useLogTransform)
set.seed(551724)
folds = sample(1:numfolds, nrow(allData$allSet), replace=T)
predictors = preparePredictors(rawData, filter)
testError = 0
testErrorInact = 0
testErrorVar = 0
testErrorRound = 0
trainError = 0
for(i in 1:numfolds) {
#set.seed(seed)
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$trainSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$trainSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
print("Training error")
gbm.train = predict(gbm.orch , newdata=data$trainSet, n.trees=trees)
trainError = trainError + evaluateModel(gbm.train, data$trainSet$total, useLogTransform)
gbm.boost = predict(gbm.orch , newdata=data$testSet, n.trees=trees)
print("Raw prediction")
testError = testError + evaluateModel(gbm.boost, data$testAnswers, useLogTransform)
print("Adjusting for inactive")
adjusted = adjustPredictionsInactive(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
print("Adjusting for invariance")
adjusted2 = adjustPredictionsInvariant(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
tries = numfolds
print(paste("Final train error raw prediction=", trainError / tries, " based on ", tries, " tries"))
print(paste("Final test error raw prediction=", testError / tries, " based on ", tries, " tries"))
print(paste("Final test error with inactive adj=", testErrorInact / tries, " based on ", tries, " tries"))
print(paste("Final test error with no variance adj =", testErrorVar / tries, " based on ", tries, " tries"))
print(paste("Final test error with rounding =", testErrorRound / tries, " based on ", tries, " tries"))
summary(gbm.orch)
#deep check
for(i in 1:length(data$testAnswers)) {
correctAnswer = data$testAnswers[[i]]
answer = adjustAnswer(gbm.boost[i])
if(abs(answer-correctAnswer) >= 1) {
print(paste("Big error for ", i, " predicted=", answer, " correct=", correctAnswer))
print(data$testSet[i, grep("total_201|account.num", colnames(data$testSet))])
}
}
print(data$allSetAll["9900",])
print(data$trainAccountsId[1487,1])
dim(data$trainAccountsId)
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$allSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$allSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
predictSet = prepareDataToPredict(data$predictors)
predictSetAll = prepareDataToPredict(allData$predictors)
predictions = predict(gbm.orch, newdata=predictSet$testSet, n.trees=trees)
#predictions = adjustPredictionsInactive(predictions, data.frame("account.id"=predictSet$accounts),
#                                predictSetAll$testSetAll)
if(useLogTransform) {
predictions = exp(predictions)-1
}
dumpResponse("ML_gbm_sub", predictSet$accounts, predictions)
topvar = summary(gbm.orch)
topPred = summary(gbm.orch)
topPred
View(topPred)
write.csv(topPred, "topPred.csv", row.names=F)
str(predictSet)
str(data$allSet)
write.csv(data$allSet, "topPred.csv", row.names=F)
write.csv(data$allSet, "viz/allSet.csv", row.names=F)
geo.account <- read.csv("data/geo.account.csv")
geo <- merge(geo.account, data$allSet, by=account.id)
str(data$allSet)
head(data$allSet)
str(data$allSetAll)
geo <- merge(geo.account, data$allSet, by=account.id)
geo <- merge(geo.account, data$allSetAll, by=account.id)
str(data$allSetAll)
geo <- merge(geo.account, data$allSetAll, by=account.id, all.y=T)
geo <- merge(geo.account, data$allSetAll, by="account.id", all.y=T)
write.csv(geo, "viz/topPred.csv", row.names=F)
# path to kaggle data and other files
setwd("C:\\Users\\milewows\\Documents\\towerProperty")
setwd("~/Documents/towerProperty") # Matt's wd path
source("config.r")
source("helpers.r")
source("data.r")
library(kernlab)
setConfigForMyEnvironment() # special helper function for Matt's environment
includeLibraries()
filter = ""
rawData = readData(FALSE)
allPredictors = preparePredictors(rawData, filter)
allData = prepareSplits(rawData, allPredictors, c(0))
filter = "199|200|2010|price.level|add_no|TELEMAN|JOHANN|ROSSINI|conc_missed|add_price|add_tickets|add_tickets_seats|section_2013_2014|multiple.subs|billing.city|is.us|relationship|outside|City|State|Lat|Long|package|section|location|geo|hotspot"
useLogTransform = FALSE
kernel="besseldot"
sigma=.001
C=100
epsilon=0.25
tol = 0.05
cross = 5
numfolds = 10
clean = T
type = "C-svc"
degree = 1
scale = 1
offset = 0
order = 10
kpar =  list(sigma=sigma, order=order, degree=degree) #"automatic" #list(sigma=sigma)
rawData = readData(useLogTransform)
polyOrder = 2
formula = prepareFormula(useLogTransform)
set.seed(551724)
folds = sample(1:numfolds, nrow(allData$allSet), replace=T)
predictors = preparePredictors(rawData, filter)
ksvm.fit = ksvm(as.factor(total)~.,data=data$trainSet, scaled=T, kernel=kernel, kpar=kpar,
C=C, epsilon=epsilon, tol=tol, cross=cross, type=type)
ksvm.fit
predictSet = prepareDataToPredict(data$predictors)
predictSetAll = prepareDataToPredict(allData$predictors)
predictions = predict(ksvm.fit, newdata=predictSet$testSet)#, n.trees=trees)
#predictions = adjustPredictionsInactive(predictions, data.frame("account.id"=predictSet$accounts),
predictSetAll$testSetAll)
data$trainSet$total = as.factor(data$trainSet$total) # change to factors
data$trainSet$total = as.factor(data$trainSet$total) # change to factors
data = prepareSplits(rawData, predictors)
trainError = 0
testError = 0
testErrorInact = 0
testErrorVar = 0
for(i in 1:numfolds) {
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
options(error=recover)
print(paste("Start ksvm fold ", i))
ksvm.fit = ksvm(total~.,data=data$trainSet, scaled=T, kernel=kernel, kpar=kpar,
C=C, epsilon=epsilon, tol=tol, cross=cross, type=type)
print(ksvm.fit)
ksvm.pred = predict(ksvm.fit, newdata=data$testSet)
ksvm.train = predict(ksvm.fit, newdata=data$trainSet)
print("Train prediction")
#trainError = trainError + evaluateModel(ksvm.train, data$trainSet$total, useLogTransform)
trainError = trainError + (1-mean(ksvm.train==data$trainSet$total))
print(trainError/i)
print("Raw prediction")
#testError = testError + evaluateModel(ksvm.pred, data$testAnswers, useLogTransform)
testError = testError + (1-mean(ksvm.pred==data$testAnswers))
print(testError/i)
#print("Adjusting for inactive")
#adjusted = adjustPredictionsInactive(ksvm.pred, data.frame("account.id"=data$testAccounts), allData$predictors)
#testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
#print("Adjusting for invariance")
#adjusted2 = adjustPredictionsInvariant(ksvm.pred, data.frame("account.id"=data$testAccounts), allData$predictors)
# testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
}
trainError = 0
testError = 0
testErrorInact = 0
testErrorVar = 0
data$trainSet$total = as.factor(data$trainSet$total) # change to factors
for(i in 1:numfolds) {
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
options(error=recover)
print(paste("Start ksvm fold ", i))
ksvm.fit = ksvm(total~.,data=data$trainSet, scaled=T, kernel=kernel, kpar=kpar,
C=C, epsilon=epsilon, tol=tol, cross=cross, type=type)
print(ksvm.fit)
ksvm.pred = predict(ksvm.fit, newdata=data$testSet)
ksvm.train = predict(ksvm.fit, newdata=data$trainSet)
print("Train prediction")
#trainError = trainError + evaluateModel(ksvm.train, data$trainSet$total, useLogTransform)
trainError = trainError + (1-mean(ksvm.train==data$trainSet$total))
print(trainError/i)
print("Raw prediction")
#testError = testError + evaluateModel(ksvm.pred, data$testAnswers, useLogTransform)
testError = testError + (1-mean(ksvm.pred==data$testAnswers))
print(testError/i)
#print("Adjusting for inactive")
#adjusted = adjustPredictionsInactive(ksvm.pred, data.frame("account.id"=data$testAccounts), allData$predictors)
#testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
#print("Adjusting for invariance")
#adjusted2 = adjustPredictionsInvariant(ksvm.pred, data.frame("account.id"=data$testAccounts), allData$predictors)
# testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
}
# path to kaggle data and other files
setwd("C:\\Users\\milewows\\Documents\\towerProperty")
