testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("Adjusting for California")
adjusted4 = adjustPredictionsGeo(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeo = testErrorGeo + evaluateModel(adjusted4, data$testAnswers, useLogTransform)
print("Adjusting for distance")
adjusted5 = adjustPredictionsGeoDist(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeoDist = testErrorGeoDist + evaluateModel(adjusted5, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
tries = numfolds
print(paste("Final train error raw prediction=", trainError / tries, " based on ", tries, " tries"))
print(paste("Final test error raw prediction=", testError / tries, " based on ", tries, " tries"))
print(paste("Final test error with inactive adj=", testErrorInact / tries, " based on ", tries, " tries"))
print(paste("Final test error with no variance adj =", testErrorVar / tries, " based on ", tries, " tries"))
print(paste("Final test error with rounding =", testErrorRound / tries, " based on ", tries, " tries"))
print(paste("Final test error with California =", testErrorGeo / tries, " based on ", tries, " tries"))
print(paste("Final test error with distance =", testErrorGeoDist / tries, " based on ", tries, " tries"))
summary(gbm.orch)
#deep check
for(i in 1:length(data$testAnswers)) {
correctAnswer = data$testAnswers[[i]]
answer = adjustAnswer(gbm.boost[i])
if(abs(answer-correctAnswer) >= 1) {
print(paste("Big error for ", i, " predicted=", answer, " correct=", correctAnswer))
print(data$testSet[i, grep("total_201|account.num", colnames(data$testSet))])
}
}
print(data$allSetAll["9900",])
print(data$trainAccountsId[1487,1])
dim(data$trainAccountsId)
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$allSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$allSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
predictSet = prepareDataToPredict(data$predictors)
predictSetAll = prepareDataToPredict(allData$predictors)
predictions = predict(gbm.orch, newdata=predictSet$testSet, n.trees=trees)
#predictions = adjustPredictionsInactive(predictions, data.frame("account.id"=predictSet$accounts),
#                                predictSetAll$testSetAll)
if(useLogTransform) {
predictions = exp(predictions)-1
}
dumpResponse("ML_gbm_sub", predictSet$accounts, predictions)
head(predictors$dSF)
predictors$dSF <- as.numeric(predictors$dSF)
View(predictors)
head(predictors$dSF)
predictors = preparePredictors(rawData, filter)
head(predictors$dSF)
head(predictors$dSF)
head(as.numeric(levels(predictors$dSF))[predictors$dSF])
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
head(predictors$dSF)
# convert dSF from factor to numeric
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
testError = 0
testErrorInact = 0
testErrorVar = 0
testErrorRound = 0
testErrorGeo = 0
testErrorGeoDist = 0
trainError = 0
for(i in 1:numfolds) {
#set.seed(seed)
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$trainSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$trainSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
print("Training error")
gbm.train = predict(gbm.orch , newdata=data$trainSet, n.trees=trees)
trainError = trainError + evaluateModel(gbm.train, data$trainSet$total, useLogTransform)
gbm.boost = predict(gbm.orch , newdata=data$testSet, n.trees=trees)
print("Raw prediction")
testError = testError + evaluateModel(gbm.boost, data$testAnswers, useLogTransform)
print("Adjusting for inactive")
adjusted = adjustPredictionsInactive(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
print("Adjusting for invariance")
adjusted2 = adjustPredictionsInvariant(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("Adjusting for California")
adjusted4 = adjustPredictionsGeo(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeo = testErrorGeo + evaluateModel(adjusted4, data$testAnswers, useLogTransform)
print("Adjusting for distance")
adjusted5 = adjustPredictionsGeoDist(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeoDist = testErrorGeoDist + evaluateModel(adjusted5, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
predictors = preparePredictors(rawData, filter)
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
head(dSF)
head(predictors$dSF)
testError = 0
testErrorInact = 0
testErrorVar = 0
testErrorRound = 0
testErrorGeo = 0
testErrorGeoDist = 0
trainError = 0
for(i in 1:numfolds) {
#set.seed(seed)
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$trainSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$trainSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
print("Training error")
gbm.train = predict(gbm.orch , newdata=data$trainSet, n.trees=trees)
trainError = trainError + evaluateModel(gbm.train, data$trainSet$total, useLogTransform)
gbm.boost = predict(gbm.orch , newdata=data$testSet, n.trees=trees)
print("Raw prediction")
testError = testError + evaluateModel(gbm.boost, data$testAnswers, useLogTransform)
print("Adjusting for inactive")
adjusted = adjustPredictionsInactive(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
print("Adjusting for invariance")
adjusted2 = adjustPredictionsInvariant(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("Adjusting for California")
adjusted4 = adjustPredictionsGeo(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeo = testErrorGeo + evaluateModel(adjusted4, data$testAnswers, useLogTransform)
print("Adjusting for distance")
adjusted5 = adjustPredictionsGeoDist(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeoDist = testErrorGeoDist + evaluateModel(adjusted5, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
tries = numfolds
print(paste("Final train error raw prediction=", trainError / tries, " based on ", tries, " tries"))
print(paste("Final test error raw prediction=", testError / tries, " based on ", tries, " tries"))
print(paste("Final test error with inactive adj=", testErrorInact / tries, " based on ", tries, " tries"))
print(paste("Final test error with no variance adj =", testErrorVar / tries, " based on ", tries, " tries"))
print(paste("Final test error with rounding =", testErrorRound / tries, " based on ", tries, " tries"))
print(paste("Final test error with California =", testErrorGeo / tries, " based on ", tries, " tries"))
print(paste("Final test error with distance =", testErrorGeoDist / tries, " based on ", tries, " tries"))
summary(gbm.orch)
#deep check
for(i in 1:length(data$testAnswers)) {
correctAnswer = data$testAnswers[[i]]
answer = adjustAnswer(gbm.boost[i])
if(abs(answer-correctAnswer) >= 1) {
print(paste("Big error for ", i, " predicted=", answer, " correct=", correctAnswer))
print(data$testSet[i, grep("total_201|account.num", colnames(data$testSet))])
}
}
print(data$allSetAll["9900",])
print(data$trainAccountsId[1487,1])
dim(data$trainAccountsId)
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$allSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$allSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
predictSet = prepareDataToPredict(data$predictors)
predictSetAll = prepareDataToPredict(allData$predictors)
predictions = predict(gbm.orch, newdata=predictSet$testSet, n.trees=trees)
#predictions = adjustPredictionsInactive(predictions, data.frame("account.id"=predictSet$accounts),
#                                predictSetAll$testSetAll)
if(useLogTransform) {
predictions = exp(predictions)-1
}
dumpResponse("MS_gbm_sub", predictSet$accounts, predictions)
names(geo)
names(geo[1])
names(geo[2]) <- "billingZipCode"
names(geo[1]) <- "accountID"
names(geo)
colnames(geo[1]) <- "accountID"
colnames(geo[2]) <- "billingZipCode"
names(geo)
colnames(geo[1])
colnames(geo)[1] <- "accountID"
colnames(geo)[2] <- "billingZipCode"
colnames(geo)
View(geo)
topPred = summary(gbm.orch)
write.csv(topPred, "topPred.csv", row.names=F)
# dump csv for mapping
geo <- merge(geo, data$allSetAll, by="account.id", all.y=T)
geo <- rawData$accounts
geo <- as.data.frame(geo[, c(1,3,5)]) #c(1,3)
table(str_length(geo[,2]))
# add missing zero to four-digit US geos
for (i in 1:19833){
if(str_length(geo[i, 2]) == 4){
geo[i,2] <- str_pad(geo[i,2], 5, "left", "0")
print(geo[i,2])
}
}
table(str_length(geo[,2]))
# trim +4 from nine-digit US geos
for (i in 1:19833){
if(str_length(geo[i, 2]) == 10){
geo[i,2] <- str_split_fixed(geo[i,2], "-", 2)[1]
print(geo[i,2])
}
}
table(str_length(geo[,2]))
## inspect
geo$billing.zip.code[geo$billing.zip.code ==""] <- NA
geo$billing.city[geo$billing.city ==""] <- NA
mp.plot(geo, y.order = TRUE, x.order = F, clustered = FALSE, gray.scale = TRUE)
## tag 1 if originally NULL in billing.zip.code and billing.city; 0 otherwise
geo$missing <- 0
geo$missing[is.na(geo$billing.zip.code)&is.na(geo$billing.city)] <- 1
table(geo$missing)
# read in and process zip code directory
zipDir <- read.csv('data/free-zipcode-database-Primary.csv',colClasses='character')
# add missing zero to four-digit US geos
for (i in 1:dim(zipDir)[[1]]){
if(str_length(zipDir[i, 1]) < 5){
zipDir[i,1] <- str_pad(zipDir[i,1], 5, "left", "0")
}
}
table(str_length(zipDir[,1]))
zipDir <- subset(zipDir, select = c(Zipcode,City,State,Lat,Long)) # keep only relevent fields
# merge city, state info to geo
geo <- merge(geo, zipDir, by.x="billing.zip.code", by.y="Zipcode",all.x=T)
names(geo)
# merge in hotspots from QGIS
hot <- read.csv("data/hotspot.csv", as.is=T)
hot <- hot[,c(4,16)]
geo <- merge(geo, hot, by="account.id", all.x=T)
# tag accounts with null billing.zip.codes as "CA" if billing.city is a California city
geo[19751,3] <- NA #removed value with troublesome "/"
caCity <- as.data.frame(table(subset(geo, State=="CA", select=City))) #list of CA cities
noZip <- is.na(geo$billing.zip.code) # index of accounts with no billing.zip.code value
df.noZip <- subset(geo, is.na(billing.zip.code))
######## this is code I can't get to work ##################
#geo$test <- "" # create temp column to test code. If it works, then update directly to geo$State
#for (i in 1:973){
#  geo$test[str_detect(as.character(geo[noZip,3]), ignore.case(as.character(caCity[i,1])))] <- "CA" # need to subset for missing
#}
#table(geo$test) # CA must be less than 2955
###########################################################
noZipIndices = which(noZip)
for(j in noZipIndices){
for (i in 1:973){
city = str_trim(tolower(as.character(geo[j,3])))
cal = str_trim(tolower(as.character(caCity[i,1])))
if(!is.na(city) && !is.na(cal) && city == cal) {
print(paste("Assigned ", j, " city ", city))
geo$State[j] <- "CA" # need to subset for missing
break
}
}
}
table(geo$State)
#######
# dump csv with geos for use as categorical predictors
write.csv(geo, "data/geo.account.csv", row.names=F)
# add distance from account to the 3 locations
geo <- read.csv("data/geo.account.csv")
# locations
dBerkley <- c(37.867005,-122.261542)
dSF <- c(37.7763272,-122.421545)
dPeninsula <- c(37.4320436,-122.1661352)
venues <- rbind(dBerkley, dSF, dPeninsula)
venues <- venues[,c(2,1)]
colnames(venues) = c("Long","Lat")
locDist <- rdist.earth(geo[,c(8,7)], venues)
geo <- cbind(geo,locDist)
## dump csv for use in data.r
write.csv(geo, "data/geo.account.csv", row.names=F)
topPred = summary(gbm.orch)
write.csv(topPred, "topPred.csv", row.names=F)
# dump csv for mapping
geo <- merge(geo, data$allSetAll, by="account.id", all.y=T)
colnames(geo)[1] <- "accountID"
colnames(geo)[2] <- "billingZipCode"
write.csv(geo, "viz/topPred.csv", row.names=F)
# dump locations for mapping
venues <- venues[,c(2,1)]
write.csv(venues, "viz/venues.csv", row.names=T)
#need to add field name to row names manually
# path to kaggle data and other files
setwd("C:\\Users\\mlewo_000\\Documents\\GitHub\\https---github.com-MatthewSchumwinger-towerProperty\\towerProperty")
setwd("~/Documents/towerProperty") # Matt's wd path
source("config.r")
source("helpers.r")
source("data.r")
library(gbm)
setConfigForMyEnvironment() # special helper function for Matt's environment
includeLibraries()
filter = ""
rawData = readData(FALSE)
allPredictors = preparePredictors(rawData, filter)
allData = prepareSplits(rawData, allPredictors, c(0))
filter = "State|3.years|4.years|199|200|2010|2011|bought|section|no.seats|conc|donation|price.level|6.years|8.years|SF|add_no|add_tickets|add_donated|TELEMAN|JOHANN|ROSSINI|add_price|conc_missed|ever.bought.subs|num.bought.ticket|add_tickets_seats|section_2013_2014|multiple.subs|billing.city|is.us|relationship|outside|Lat|Long|geo|Peninsula|Berkley|hotspot|City|missing"
useLogTransform = F
trees = 3375
bagfrac = 0.5
trainfrac = 1.0
shrinkage = 0.001
depth = 9
distrib = "tdist"
minobsinnode = 5
df = 8
numfolds = 10
clean = T
rawData = readData(useLogTransform)
# for some reasom gbm is not picking that up in the function
polyOrder = 2
formula = prepareFormula(useLogTransform)
set.seed(551724)
folds = sample(1:numfolds, nrow(allData$allSet), replace=T)
predictors = preparePredictors(rawData, filter)
# convert dSF from factor to numeric
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
testError = 0
testErrorInact = 0
testErrorVar = 0
testErrorRound = 0
testErrorGeo = 0
testErrorGeoDist = 0
trainError = 0
for(i in 1:numfolds) {
#set.seed(seed)
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$trainSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$trainSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
print("Training error")
gbm.train = predict(gbm.orch , newdata=data$trainSet, n.trees=trees)
trainError = trainError + evaluateModel(gbm.train, data$trainSet$total, useLogTransform)
gbm.boost = predict(gbm.orch , newdata=data$testSet, n.trees=trees)
print("Raw prediction")
testError = testError + evaluateModel(gbm.boost, data$testAnswers, useLogTransform)
print("Adjusting for inactive")
adjusted = adjustPredictionsInactive(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
print("Adjusting for invariance")
adjusted2 = adjustPredictionsInvariant(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("Adjusting for California")
adjusted4 = adjustPredictionsGeo(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeo = testErrorGeo + evaluateModel(adjusted4, data$testAnswers, useLogTransform)
print("Adjusting for distance")
adjusted5 = adjustPredictionsGeoDist(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeoDist = testErrorGeoDist + evaluateModel(adjusted5, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
str(predictors$dSF)
filter = "State|3.years|4.years|199|200|2010|2011|bought|section|no.seats|conc|donation|price.level|6.years|8.years|add_no|add_tickets|add_donated|TELEMAN|JOHANN|ROSSINI|add_price|conc_missed|ever.bought.subs|num.bought.ticket|add_tickets_seats|section_2013_2014|multiple.subs|billing.city|is.us|relationship|outside|Lat|Long|geo|Peninsula|Berkley|hotspot|City|missing"
useLogTransform = F
trees = 3375
bagfrac = 0.5
trainfrac = 1.0
shrinkage = 0.001
depth = 9
distrib = "tdist"
minobsinnode = 5
df = 8
numfolds = 10
clean = T
rawData = readData(useLogTransform)
# for some reasom gbm is not picking that up in the function
polyOrder = 2
formula = prepareFormula(useLogTransform)
set.seed(551724)
folds = sample(1:numfolds, nrow(allData$allSet), replace=T)
predictors = preparePredictors(rawData, filter)
# convert dSF from factor to numeric
predictors$dSF <-as.numeric(levels(predictors$dSF))[predictors$dSF]
testError = 0
testErrorInact = 0
testErrorVar = 0
testErrorRound = 0
testErrorGeo = 0
testErrorGeoDist = 0
trainError = 0
for(i in 1:numfolds) {
#set.seed(seed)
data = prepareSplits(rawData, predictors, which(folds == i))
if(clean) {
data = cleanData(data)
}
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$trainSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$trainSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
print("Training error")
gbm.train = predict(gbm.orch , newdata=data$trainSet, n.trees=trees)
trainError = trainError + evaluateModel(gbm.train, data$trainSet$total, useLogTransform)
gbm.boost = predict(gbm.orch , newdata=data$testSet, n.trees=trees)
print("Raw prediction")
testError = testError + evaluateModel(gbm.boost, data$testAnswers, useLogTransform)
print("Adjusting for inactive")
adjusted = adjustPredictionsInactive(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorInact = testErrorInact + evaluateModel(adjusted, data$testAnswers, useLogTransform)
print("Adjusting for invariance")
adjusted2 = adjustPredictionsInvariant(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorVar = testErrorVar + evaluateModel(adjusted2, data$testAnswers, useLogTransform)
print("Adjusting for rounding")
adjusted3 = adjustPredictionsRound(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorRound = testErrorRound + evaluateModel(adjusted3, data$testAnswers, useLogTransform)
print("Adjusting for California")
adjusted4 = adjustPredictionsGeo(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeo = testErrorGeo + evaluateModel(adjusted4, data$testAnswers, useLogTransform)
print("Adjusting for distance")
adjusted5 = adjustPredictionsGeoDist(gbm.boost, data.frame("account.id"=data$testAccounts), allData$predictors)
testErrorGeoDist = testErrorGeoDist + evaluateModel(adjusted5, data$testAnswers, useLogTransform)
print("End fold")
print("End fold")
print("End fold")
}
tries = numfolds
print(paste("Final train error raw prediction=", trainError / tries, " based on ", tries, " tries"))
print(paste("Final test error raw prediction=", testError / tries, " based on ", tries, " tries"))
print(paste("Final test error with inactive adj=", testErrorInact / tries, " based on ", tries, " tries"))
print(paste("Final test error with no variance adj =", testErrorVar / tries, " based on ", tries, " tries"))
print(paste("Final test error with rounding =", testErrorRound / tries, " based on ", tries, " tries"))
print(paste("Final test error with California =", testErrorGeo / tries, " based on ", tries, " tries"))
print(paste("Final test error with distance =", testErrorGeoDist / tries, " based on ", tries, " tries"))
summary(gbm.orch)
#deep check
for(i in 1:length(data$testAnswers)) {
correctAnswer = data$testAnswers[[i]]
answer = adjustAnswer(gbm.boost[i])
if(abs(answer-correctAnswer) >= 1) {
print(paste("Big error for ", i, " predicted=", answer, " correct=", correctAnswer))
print(data$testSet[i, grep("total_201|account.num", colnames(data$testSet))])
}
}
print(data$allSetAll["9900",])
print(data$trainAccountsId[1487,1])
dim(data$trainAccountsId)
if(distrib == "tdist") {
gbm.orch = gbm(formula, data = data$allSet, distribution = list(name="tdist", df=df),
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
} else {
gbm.orch = gbm(formula, data = data$allSet, distribution = distrib,
bag.fraction = bagfrac, train.fraction = trainfrac,
shrinkage = shrinkage, n.trees = trees, interaction.depth = depth, n.minobsinnode=minobsinnode)
}
summary(gbm.orch)
predictSet = prepareDataToPredict(data$predictors)
predictSetAll = prepareDataToPredict(allData$predictors)
predictions = predict(gbm.orch, newdata=predictSet$testSet, n.trees=trees)
#predictions = adjustPredictionsInactive(predictions, data.frame("account.id"=predictSet$accounts),
#                                predictSetAll$testSetAll)
if(useLogTransform) {
predictions = exp(predictions)-1
}
dumpResponse("MS_gbm_sub", predictSet$accounts, predictions)
